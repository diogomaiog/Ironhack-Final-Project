{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I take inputs from the user and make a prediction, based on the models created in \n",
    "# the Main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Diogo\n",
      "[nltk_data]     Gonçalves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Diogo Gonçalves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Diogo\n",
      "[nltk_data]     Gonçalves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Diogo\n",
      "[nltk_data]     Gonçalves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of valid movie genres\n",
    "valid_genres = ['action','adventure','animation','biography','comedy','crime','documentary',\n",
    "          'drama','family','fantasy','history','horror','music','musical','mystery',\n",
    "          'news','romance','sci-fi','sport','thriller','war', 'western']\n",
    "\n",
    "valid_ratings = ['Approved','G','NC-17','Not Rated','PG','PG-13','R','TV-14','TV-G','TV-MA','TV-PG',\n",
    "                 'Unrated','X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load movies\n",
    "#movies = pickle.load(open('moviesROI.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of valid actors\n",
    "#valid_actors = set(movies.actor1.unique())\n",
    "#valid_actors = valid_actors | set(movies.actor2.unique())\n",
    "#valid_actors = valid_actors | set(movies.actor3.unique())\n",
    "#valid_actors = list(valid_actors)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of valid directors\n",
    "#valid_directors = list(set(movies.directors.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing table to translate ids to names\n",
    "# name.basics.tsv.gz – Contains the following information for names:\n",
    "# nconst (string) - alphanumeric unique identifier of the name/person\n",
    "# primaryName (string)– name by which the person is most often credited\n",
    "\n",
    "#path = 'Data/'\n",
    "#names = pickle.load(open(path+\"name.basics.sav\",\"rb\"))\n",
    "#names = names[['nconst', 'primaryName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding primary name to valid directors and valid actors\n",
    "\n",
    "# creating dfs\n",
    "#actors = pd.DataFrame(valid_actors, columns=['actorID'])\n",
    "#directors = pd.DataFrame(valid_directors, columns=['directorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging name to dfs\n",
    "#actors = pd.merge(actors,names,left_on='actorID',right_on='nconst')\n",
    "#directors = pd.merge(directors,names,left_on='directorID',right_on='nconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "#actors.drop(columns='actorID',inplace=True)\n",
    "#directors.drop(columns='directorID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating validation lists with names instead of ids\n",
    "#valid_actors = actors['primaryName'].to_list()\n",
    "#valid_directors = directors['primaryName'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resulting tables so I don't have to run this every time\n",
    "#pickle.dump(valid_actors,open('valid_actors.pkl',\"wb\"))\n",
    "#pickle.dump(valid_directors,open('valid_directors.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved tables\n",
    "valid_actors = pickle.load(open('valid_actors.pkl',\"rb\"))\n",
    "valid_directors = pickle.load(open('valid_directors.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    '''\n",
    "    returns a dictionary with the user inputs\n",
    "    '''\n",
    "\n",
    "    # year\n",
    "    def valid_year(year):\n",
    "        try:\n",
    "            year = int(year)\n",
    "            if year >= 1980 and year < 2025:\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    year = input(\"Please enter the year your movie will come out :\\n\")\n",
    "    while not valid_year(year):\n",
    "        print('Please enter a valid year between 1980 and 2025.')\n",
    "        year = input(\"Please enter the year your movie will come out :\\n\")\n",
    "\n",
    "    year = int(year)\n",
    "\n",
    "    # runtimeMinutes\n",
    "    def valid_runtimeMinutes(minutes):\n",
    "        try:\n",
    "            minutes = int(minutes)\n",
    "            if minutes > 0 and minutes < 300:\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    runtimeMinutes = input(\"Please enter the runtime in minutes of your movie:\\n\")\n",
    "    while not valid_runtimeMinutes(runtimeMinutes):\n",
    "        print('Please enter a valid runtime between 0 and 300 minutes.')\n",
    "        runtimeMinutes = input(\"Please enter the runtime in minutes of your movie:\\n\")\n",
    "\n",
    "    runtimeMinutes = int(runtimeMinutes)\n",
    "\n",
    "    # genres\n",
    "    def valid_yn(yn):\n",
    "        if yn == 'y' or yn =='n':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def request_genre():\n",
    "        genre = input(\"Please enter one of your movie genres:\\n\")\n",
    "        genre = genre.lower()\n",
    "        while genre not in valid_genres:\n",
    "            print('That is not a valid genre.')\n",
    "            genre = input(\"Please enter one of your movie genres:\\n\")\n",
    "            genre = genre.lower()\n",
    "        genres.add(genre)\n",
    "        return\n",
    "\n",
    "    def request_yn():    \n",
    "            more = input(\"Do you want to add more genres to your movie?(y/n)\\n\")\n",
    "            while not valid_yn(more):\n",
    "                more = input(\"Do you want to add more genres to your movie?(y/n)\\n\")\n",
    "            return more\n",
    "\n",
    "\n",
    "    genres = set()\n",
    "    request_genre()\n",
    "    while request_yn() == 'y':\n",
    "        request_genre()\n",
    "\n",
    "    # rating\n",
    "    rating = input(\"Please enter your movie rating:\\n\")\n",
    "    while rating not in valid_ratings:\n",
    "        print('That is not a valid rating.')\n",
    "        rating = input(\"Please enter your movie rating:\\n\")\n",
    "\n",
    "    # director\n",
    "    director = input(\"Please enter your movie director:\\n\")\n",
    "    while director not in valid_directors:\n",
    "        print('That is not a valid director.')\n",
    "        director = input(\"Please enter your movie director:\\n\")\n",
    "\n",
    "    # actors\n",
    "    def request_actor():\n",
    "        actor = input(\"Please enter one of your movie actors:\\n\")\n",
    "        while actor not in valid_actors:\n",
    "            print('That is not a valid actor.')\n",
    "            actor = input(\"Please enter one of your movie actors:\\n\")\n",
    "        actors.add(actor)\n",
    "        return\n",
    "\n",
    "    def request_yn_actor():    \n",
    "            more = input(\"Do you want to add more actors to your movie?(y/n)\\n\")\n",
    "            while not valid_yn(more):\n",
    "                more = input(\"Do you want to add more actors to your movie?(y/n)\\n\")\n",
    "            return more\n",
    "\n",
    "    actors = set()\n",
    "    request_actor()\n",
    "    while request_yn_actor() == 'y' and len(actors) < 3:\n",
    "        request_actor()\n",
    "    if len(actors) == 3:\n",
    "        print('''Sorry, you can't add any more actors.''')\n",
    "\n",
    "    story = input(\"Briefly describe your movie plot (around 150 words).\\n\")\n",
    "    return {'story':story,'actors':actors,'director':director,'rating':rating,'genres':genres,'runtimeMinutes':runtimeMinutes,'year':year}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Naive Bayes classifier on story\n",
    "\n",
    "# Transform the string into a valid model input\n",
    "\n",
    "# defining necessary funtions\n",
    "def clean_up(s):\n",
    "    \"\"\"\n",
    "    Cleans up numbers, URLs, and special characters from a string.\n",
    "\n",
    "    Args:\n",
    "        s: The string to be cleaned up.\n",
    "\n",
    "    Returns:\n",
    "        A string that has been cleaned up.\n",
    "    \"\"\"\n",
    "    # turn to lowercase   \n",
    "    s = s.lower()\n",
    "    #remove URLs\n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    s = re.sub(regex,\"\",s)\n",
    "    #replace special characters with spaces\n",
    "    s = re.sub(r'([^a-zA-Z ]+?)', ' ', s)\n",
    "    #removes leading and traling whitespaces\n",
    "    s = s.strip()\n",
    "    #removes multiple white spaces\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    return s\n",
    "\n",
    "def tokenize(s):\n",
    "    \"\"\"\n",
    "    Tokenize a string.\n",
    "\n",
    "    Args:\n",
    "        s: String to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        A list of words as the result of tokenization.\n",
    "    \"\"\"\n",
    "    #return s.split(\" \")\n",
    "    return nltk.word_tokenize(s)\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist \n",
    "\n",
    "def stem_and_lemmatize(l):\n",
    "    \"\"\"\n",
    "    Perform stemming and lemmatization on a list of words.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after being stemmed and lemmatized.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in l]\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    \"\"\"\n",
    "    Remove English stopwords from a list of strings.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after stop words are removed.\n",
    "    \"\"\"\n",
    "    return [word for word in l if not word in stopwords.words()]\n",
    "\n",
    "def process_text(text):\n",
    "    '''\n",
    "    Cleans-up, tokenizes, gets word net position, stems and lemmatizes and then removes the stopwords for a story text.\n",
    "    Returns the list of resulting 'words'\n",
    "    '''\n",
    "    return remove_stopwords(stem_and_lemmatize(tokenize(clean_up(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to import the list of top5000 words\n",
    "top5000 = pickle.load(open('top5000.pkl',\"rb\"))\n",
    "\n",
    "# we need a function that finds the word features (our top most common words)\n",
    "# in the text\n",
    "def find_features(text):\n",
    "    words = set(text)\n",
    "    features = {}\n",
    "    for w in top5000:\n",
    "        features[w] = (w in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the classifier we created\n",
    "classifier = pickle.load(open('NBClassifier.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the prediction\n",
    "def nlp_classifier(story):\n",
    "    return classifier.classify(find_features(process_text('story')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a table, that contains the stars and directors IMDB and ROI to be able to consult it faster \n",
    "# (instead of computing these scores each time)\n",
    "# Then I'll pickle it and assume it as an input of this notebook\n",
    "\n",
    "'''\n",
    "# tables with the average rating of the movies a actor is in, by column\n",
    "# creating table with actor rating\n",
    "actors1 = pd.pivot_table(movies, values = 'averageRating', index = 'actor1', aggfunc = 'mean')\n",
    "actors2 = pd.pivot_table(movies, values = 'averageRating', index = 'actor2', aggfunc = 'mean')\n",
    "actors3 = pd.pivot_table(movies, values = 'averageRating', index = 'actor3', aggfunc = 'mean')\n",
    "actors_rating = pd.concat([actors1, actors2, actors3]).groupby(level=0).mean()\n",
    "actors_rating.reset_index(inplace=True)\n",
    "actors_rating.drop(actors_rating.index[0],inplace=True)\n",
    "actors_rating = pd.merge(actors_rating,names,left_on='index',right_on='nconst')\n",
    "actors_rating.drop(columns='index',inplace=True)\n",
    "pickle.dump(actors_rating,open('actors_rating.pkl',\"wb\"))\n",
    "#creating table with directors rating\n",
    "directors_rating = pd.pivot_table(movies, values = 'averageRating', index = 'directors', aggfunc='mean')\n",
    "directors_rating.reset_index(inplace=True)\n",
    "directors_rating = pd.merge(directors_rating,names,left_on='directors',right_on='nconst')\n",
    "directors_rating.drop(columns='directors',inplace=True)\n",
    "pickle.dump(directors_rating,open('directors_rating.pkl',\"wb\"))\n",
    "\n",
    "# creating table with actor ROI\n",
    "actors1 = pd.pivot_table(movies, values = 'ROI', index = 'actor1', aggfunc = 'mean')\n",
    "actors2 = pd.pivot_table(movies, values = 'ROI', index = 'actor2', aggfunc = 'mean')\n",
    "actors3 = pd.pivot_table(movies, values = 'ROI', index = 'actor3', aggfunc = 'mean')\n",
    "actorsROI = pd.concat([actors1, actors2, actors3]).groupby(level=0).mean()\n",
    "actorsROI.reset_index(inplace=True)\n",
    "actorsROI = pd.merge(actorsROI,names,left_on='index',right_on='nconst')\n",
    "actorsROI.drop(columns='index',inplace=True)\n",
    "pickle.dump(actorsROI,open('actorsROI.pkl',\"wb\"))\n",
    "# creating table with director ROI\n",
    "directorsROI = pd.pivot_table(movies, values = 'ROI', index = 'directors', aggfunc='mean')\n",
    "directorsROI.reset_index(inplace=True)\n",
    "directorsROI = pd.merge(directorsROI,names,left_on='directors',right_on='nconst')\n",
    "directorsROI.drop(columns='directors',inplace=True)\n",
    "directorsROI.head()\n",
    "pickle.dump(directorsROI,open('directorsROI.pkl',\"wb\"))\n",
    "'''\n",
    "# since actors can be directors and vice-versa, and to mimic the logic of the \n",
    "# data used to build the model I had to keep the tables separate for actors and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the previously created tables for ROI and Rating of people\n",
    "actors_rating = pickle.load(open('actors_rating.pkl',\"rb\"))\n",
    "directors_rating = pickle.load(open('directors_rating.pkl',\"rb\"))\n",
    "actorsROI = pickle.load(open('actorsROI.pkl',\"rb\"))\n",
    "directorsROI = pickle.load(open(\"directorsROI.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing starsIMDB, directorIMDB, starsROI, directorROI\n",
    "def mean_ROI(names):\n",
    "    '''\n",
    "    takes a list of actors names and returns the average of average ROIs for the names provided\n",
    "    '''\n",
    "    values = []\n",
    "    for name in names:\n",
    "        values.append(float(actorsROI[actorsROI.primaryName == name]['ROI']))\n",
    "    return sum(values)/len(values)\n",
    "\n",
    "def dir_ROI(director_name):\n",
    "    '''\n",
    "    takes the name of a director and returns his/her average ROI\n",
    "    '''\n",
    "    return float(directorsROI[directorsROI.primaryName == director_name]['ROI'])\n",
    "\n",
    "def mean_IMDB(names):\n",
    "    '''\n",
    "    takes a list of actors and returns the average of average IMDB ratings \n",
    "    for the names provided\n",
    "    '''\n",
    "    values = []\n",
    "    for name in names:\n",
    "        values.append(float(actors_rating[actors_rating.primaryName == name]['averageRating']))\n",
    "    return sum(values)/len(values)\n",
    "\n",
    "def dir_IMDB(director_name):\n",
    "    '''\n",
    "    takes the name of a director and returns his/her average IMDB score\n",
    "    '''\n",
    "    return float(directors_rating[directors_rating.primaryName == director_name]['averageRating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all inputs I can on a DF\n",
    "def process_inputs(raw_inputs):\n",
    "    '''\n",
    "    takes a dictionary with user inputs, returns a dataframe ready to be\n",
    "    used as input for the classifier model\n",
    "    '''\n",
    "    # creating empty df:\n",
    "    inputs = pd.DataFrame(columns = ['startYear','runtimeMinutes','action','adventure','animation','biography','comedy','crime',\n",
    "                                     'documentary','drama','family','fantasy','history','horror','music','musical','mystery',\n",
    "                                     'news','romance','sci-fi','sport','thriller','war','western','result','Approved','G',\n",
    "                                     'NC-17','Not Rated','PG','PG-13','R','TV-14','TV-G','TV-MA','TV-PG','Unrated','X',\n",
    "                                     'starsIMDB','directorIMDB','starsROI','directorROI','NLPclass'], index =[0])\n",
    "\n",
    "    # populating a dic that I will later add as a row on the inputs df\n",
    "    inputs_dic = {}\n",
    "    inputs_dic['startYear'] = raw_inputs['year']\n",
    "    inputs_dic['runtimeMinutes'] = raw_inputs['runtimeMinutes']\n",
    "    for g in valid_genres:\n",
    "        if g in raw_inputs['genres']: \n",
    "            inputs_dic[g] = 1\n",
    "        else:\n",
    "            inputs_dic[g] = 0\n",
    "    for r in valid_ratings:\n",
    "        if r == raw_inputs['rating']: \n",
    "            inputs_dic[r] = 1\n",
    "        else:\n",
    "            inputs_dic[r] = 0\n",
    "    inputs_dic['starsIMDB'] = mean_IMDB(raw_inputs['actors'])\n",
    "    inputs_dic['directorIMDB'] = dir_IMDB(raw_inputs['director'])\n",
    "    inputs_dic['starsROI'] = mean_ROI(raw_inputs['actors'])\n",
    "    inputs_dic['directorROI'] = dir_ROI(raw_inputs['director'])\n",
    "    inputs_dic['NLPclass'] = nlp_classifier(raw_inputs['story'])\n",
    "\n",
    "    # creating a datframe and changing dtypes \n",
    "    inputs.loc[0] = pd.Series(inputs_dic)\n",
    "    inputs.drop(columns='result',inplace=True)\n",
    "    inputs = inputs.astype('float64')\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('XGBClassifier.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(inputs):\n",
    "    '''\n",
    "    takes inputs (a single row dataframe) and returns the predicted\n",
    "    result flop, regular or blockbuster\n",
    "    '''\n",
    "    p = int(model.predict(inputs))\n",
    "    if p == 0:\n",
    "        return 'Flop'\n",
    "    if p == 1:\n",
    "        return 'Regular'\n",
    "    if p == 2:\n",
    "        return 'Blockbuster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the year your movie will come out :\n",
      "1999\n",
      "Please enter the runtime in minutes of your movie:\n",
      "99\n",
      "Please enter one of your movie genres:\n",
      "war\n",
      "Do you want to add more genres to your movie?(y/n)\n",
      "ñ\n",
      "Do you want to add more genres to your movie?(y/n)\n",
      "n\n",
      "Please enter your movie rating:\n",
      "R\n",
      "Please enter your movie director:\n",
      "Steven Spielberg\n",
      "Please enter one of your movie actors:\n",
      "Tom Hanks\n",
      "Do you want to add more actors to your movie?(y/n)\n",
      "n\n",
      "Briefly describe your movie plot (around 150 words).\n",
      "A piece of dog poop.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Blockbuster'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_outcome(process_inputs(get_inputs()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
